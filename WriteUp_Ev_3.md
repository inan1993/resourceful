# Evolution 3 - Write Up

### Retrospective


- Identify Good design choices
- Identify Bad design choices
- Did the design decisions effect the them and how?
- What would you have done differently



### Analysis

- Justify current design decisions.
- How will these decisions help in the future?
- Identify weaknesses and strengths?
- How would you fix the weaknesses in the future?

------------
- Grammar and writing.
- Organization and neatness.
- Supplementary aid (diagrams, images, charts...)



--------------

--------------


We had to switch from a 'blacklist' style permission system to a more group-based approach, as the requirements of the third evolution were not at all conducive to our original system. The groups component needed to be more versatile. 

In our previous designs we had not fully implemented the email capacity of the site, and in this evolution it became clear that we needed to revisit emails. A functioning email system is essential to approving and changing reservations so we had to get an email server running that could send emails many times per minute to the appropriate addresses. We had to cover many edge cases with this system that required the application of thorough logic, and in this we were successful.

The email system is realized by SynchedCron and an external mailing server. SynchedCron is a Meteor package which schedules jobs and tasks that is added to a certain Collection and emails were scheduled this way. In order to send the emails, there had to be a deidcated SMTP server to send out the emails. SynchedCron could integerate with several mailing platforms and Gmail was chosen mainly because its SMTP settings were already configured as compared to Mailgun or Sendgrid which required a domain configuration first. One interesting thing to note is the speed by which the server sends out emails. Gmail is extremely efficient when sending to other Gmail acocunts but takes significantly longer when sending to Duke email accounts. This has to do with server locations and scheduling choices and further exploration into mailing efficiency can be explored in the next Evolution.

What we have found is that our design choice, namely the packages we used to interact with our databases, made the devlopement of an **API** difficult.  The autoform package we use is front-end based, with all the backend submission take care of. This is great for the user-facing side of our software, but made exposing the functions to update the databases properly a difficult task. Currently, the Restivus package we are attempting to implement is not integrating with our security/roles requirements effectively, and we are having trouble figuring out how to deal with this since previously our database maniuplation was wrapped up in the autoform package. We developing a middle layer of security to check roles on user API calls so that only people who are allowed to see a resource, reservatoin, etc., can see it. 

This current design is a departure from a basic CRUD app, as multiple resources are now able to be reserved under single reservations, and we had to implement and elaborate approval system for reservations. At the core, the operations on the database remain the same, but now there are intermediate stages in between user making a reuest and the CRUD calls being made on the database.


A design decision we made that effected our ability to imeplement Duke **OAuth** was to use the account-oauth meteor package. By using the default package and not writing our own login console we were at the mercy of the feature available through the package. The package made it easy to use external authentication from google, facebook and twitter. But to use a custom external authenitcation service we needed to write our own login handler. It was not trivial to simply go back and just write our own login function because using the account-oauth package meant that our user creation (in the database) was closely tied to this. Another thing we did not consider that the package was relatively new and so there was very little support for it and so writing the loginHandler was not easy, it required a lot of debugging and testing. Our current design gets back a authenticated netid from the Duke OAuth2 service and simply checks if the user exists in the user database. If it doesn't contain the user, he is added and then logged into the app with a resume token. This may effect the permissions of (externally authenticated) users in the future because when adding the authenticated netIds into the database we are not creating the users the same way the account-oauth meteor package is.


We also had a lot of problems with **hosting** and deloying the app. We made the decision of using Meteor's free hosting to host our meteor app. However we didn't realize that there was a time limit on the hosting which makes sense, and our free hosting account recently expired. We could have simply registered another account and continued with their Galaxy environment. However we decided to move away from this temporary measure and use an actual deployment platform (PaaS). We chose AWS at first but we had a problem with the versioning of our packages. We then decided to use Heroku. However this didn't work with out meteor app as well, after some digging around we found that the Heroku buildpacks tht were available for Meteor were not compatible with the new version of Meteor that had be released a couple of days ago. So to use AWS or Heroku we would have to use an older version of Meteor. We were not okay with this since it might deprecate some of the packages whose feature we are currently utilizing. We then found a service called Modulus that worked with our app. However again here we have only $15 worth of free credits. An negative effect of not having a fixed domain is that our redirect URL for the Duke OAuth login keeps changing. And because the redirect URL must be approved each time it is changed we could not get our newest URL approved in time for the demo even though the feature worked. Looking back we should have deployed our app on a Duke machine which we could set up as per our requirements, and was free to use. We should not have shyed away from the extra work of setting up a custom environment. However I am still not convinced that that would be more efficient since there is not a lot of support for setting up your own server for hosting Meteor apps.

We also recently realized that **testing** is slowly becoming a more vital part of the application. The bigger and more complex the app gets the greater the need is for testing. Previously, till before Evolution 3, we had basic features which could be tested manaully and there were only a few edge cases that needed to be checked. We did not feel the need to spend the time on implementing a testing framework for our app since we would yield a much higher return on time invested if we spent it on implementing new features and cleaning up our code base. But as new requirements are added we have had to go back and change some parts of the code. Not having tests implemented has cost us precious time now, because changing old code breaks certain functionality and we need to spend additional hours debugging to find these bugs. Whereas if we had our testing framework we would know as soon as a change cause a bug and we would be able to correct it. Also there are now numerous more edge cases that cannot be as easily tested, and require non-trivial effore and time to perform. These could be so much more robust, extensive and faster if they were automated. We have decided to assign one person to testing for the future evolution. Also with the new version release of Meteor there has been an announcement in new testing features and improvement in testing modules. We require further research to decide what the trade-offs are between the various testing frameworks we can use. However the new unit-testing and integration-testing modules released look promising. The full-app test mode is especially interesting, which makes it easier to write integration tests for the entire stack. This testing will also help us test the reactivity of our app which may help us finally figure out why our datasource is acting so strangely. 

Considering our past design choices, two stick out as having made our lives significantly more difficult: our implementation of group level permissions in Evolution 2, and our decision to use Iron Router as our routing package.

Our implementation of group permissions in Evolution 2 involved attempting to use one design patterns instead of two - adding a specific field to the user database table to track user level permissions, and then also using a separate groups table to keep track of what members were in a group, but tracking the group members permissions through the same user table entries.  This was a disastrous decision.  Though it initially seemed like we would be reducing complexity by only having to look in one place for a user's role, it actually meant that we needed to keep iterating over all the members of a group to change their permissions whenever a group was changed - this led to several edge cases that were missed and subsequent bugs in our demos.  In this evolution, we changed Groups to have their own set of permissions, and now check those permissions along with the user level permissions.  While this looks a little less clean in the code, it has greatly reduced the number of edge cases and bugs involved with group permissions.  The time we wasted here during Evolution 2 delayed our ability to implement a page where user managers could change permissions for an individual user instead of an entire group - now, the entire backend is built for this almost by default, and we just need to add an html page for the user to be able to make these changes from.  This is more robust, as our business logic is better separated from the specifics of who is accessing the app.

Going forward, a major goal is to replace Iron Router with Flow Router - Flow Router better separates the actual routing within the app from template rendering.  Template rendering is how the individual pages of our app get pieced together - having Iron Router try to handle this as well as the actual routing has caused several bugs for us, most noteably a quick "flash" of the admin sign up screen whenever there is any latency.  This is caused by Iron Router having a short delay in routing while it processes templating logic - by separating these two functions, we can avoid that delay and avoid the bug.  Iron Router has several bugs, and represents a case of bad encapsulation that has been largely abandoned by the Meteor community in favor of FlowRouter.  Though we initially chose Iron Router because we were more comfortable with it, it now seems the negatives of continuing to use it outweigh the familiarity benefits.

Another major bug that has been around since Evolution 2 is the fact that our data sources are not reactive - one of our primary motivations for choosing Meteor over a simple MEAN stack is the implementation of reactive data sources, described below.

![Image of Meteor Dataflow](https://camo.githubusercontent.com/dba00266cf8c281e32e03a52a246068e37884412/687474703a2f2f626c6f6e6b2e636f2e73332e616d617a6f6e6177732e636f6d2f696d672f72656163746976652d6d6574656f722d64617461322e6a7067)

As you can see, Meteor stores each collection object locally in a Mini-Mongo database, which is updated either by User actions or by a push from the Meteor server.  Since the collection is updated on demand, there is no need to continually refresh the page or make additional requests to the database - changes in the database will be synced with the client in real time.

For some of our pages, this works well - you can see if you try to approve or reject reservations in our approval queue, they appear and disappear without a page reload.  However, our main dashboard consisting of our search bar and list of resources does not update without a hard refresh of the page - this is due to the package we are using to run our search function essentially hijacking the reactive data source without providing us with one of our own.  To fix this, we either need to reimplement the reactive data source ourselves or find/create a new search function.  While neither is appealing, we will likely end up creating our own reactive search, as the selection of packages currently available is quite sparse.

In general, this point leads to something we have learned about Meteor throughout the past few weeks - working with new software and new frameworks is difficult.  For example, as mentioned above, Meteor did not have complete support for Integration Testing or Unit Testing outside of third-party packages until earlier this week.  Also as mentioned, this new release broke both Heroku and AWS deployment bundles, so we were unable to deploy to live in time for our demo.  These sorts of growing pains are more common with software that hasn't been tested as thoroughly and isn't used in mission critical applications, like Java or Node.js.  Since the Meteor Development Group is still figuring out their own business model, we have had to cope with the shutdown of the free tier of their deployment service, as well as code pushes that sometimes break old functionality.  While this might be ok for a class, it is a very relevant design decision when it comes to how reliable the system you're designing on top of is - for us, this reliability has been sparse.

A few final pieces that are major problems for our code right now are encapsulation, code reuse, and code quality.  We will need to spend the first week of the new sprint not only setting better goals and timelines for ourselves, but working to write comments throughout our code - right now, because of the rushed nature of our work, the code is not well documented.  Further, this is impacting our ability to work effectively because each sprint complicates the code base, making the exact line where a bug might have been previously solved harder and harder to find.  There are a few instances in our code of sections that have been copy and pasted to work together - these need to be refactored into separate methods, and moved from the client to the server in order to provide security, since in Meteor client side code can be bypassed, which could lead to our site getting taken down.  Finally, the general structure of our code needs to be reworked, particularly the templates section.  While the folder names made sense for evolution 1, they have not really been revamped since - without refactoring, it will take longer and longer to find where things should go.

We did a few things very well this sprint - for one, we were better able to schedule our time and got a much larger number of the requirements completed.  Our ability to integrate Oauth logins without needing a separate database table shows how Meteor packages are extensible, and can be reused to work with a number of providers in a number of use cases.  Further, our consistent use of strictly defined schema for our databases has enabled us to quickly hunt down bugs by seeing when something was being erroneously inserted before it corrupted our data.  We have also made use of a Meteor debugging tool called Mongol that greatly helped us by letting us see the actual active database contents, and debug quickly by inserting directly into it.  Overall, we are confident in our design going forward, having fixed many of the issues that impacted us so heavily in Evolution 2 - that said, there is still work to be done, particularly from the perspective of reducing code reuse by better encapsulating our modules.
